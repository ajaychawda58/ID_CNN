{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "plain-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import utils, transforms, datasets\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "\n",
    "from transforms import ToTensor, Resize, Compose, testTensor\n",
    "from data.kitti_dataset import KITTI\n",
    "from backbone.backbone_vgg import vgg16, vgg11, vgg13, vgg19\n",
    "from backbone.backbone_resnet import resnet18, resnet34\n",
    "from models.faster_rcnn_mod import FasterRCNN\n",
    "from models.mask_rcnn_mod import MaskRCNN\n",
    "from models.keypoint_rcnn_mod import KeypointRCNN\n",
    "from models.retinanet_mod import RetinaNet\n",
    "\n",
    "from ID.intrinsic_dimension import estimate, block_analysis\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "corporate-albany",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = vgg16(pretrained=False).features\n",
    "backbone.out_channels = 512\n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5,1.0,2.0),)) \n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "competitive-briefing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "model_path = os.path.join(root, \"trained_model\", \"kitti\", \"retinanet\", \"vgg16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artificial-august",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = FasterRCNN(backbone, num_classes=10,rpn_anchor_generator= anchor_generator, box_roi_pool=roi_pooler )\n",
    "model = RetinaNet(backbone, num_classes=10, anchor_generator=anchor_generator)\n",
    "model.load_state_dict(torch.load(os.path.join(model_path, 'model.pt'), map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "oriental-coffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetinaNet(\n",
       "  (backbone): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (anchor_generator): AnchorGenerator()\n",
       "  (head): RetinaNetHead(\n",
       "    (classification_head): RetinaNetClassificationHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): ReLU()\n",
       "      )\n",
       "      (cls_logits): Conv2d(512, 150, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (regression_head): RetinaNetRegressionHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (7): ReLU()\n",
       "      )\n",
       "      (bbox_reg): Conv2d(512, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "further-bronze",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone.0.weight \t torch.Size([64, 3, 3, 3])\n",
      "backbone.0.bias \t torch.Size([64])\n",
      "backbone.2.weight \t torch.Size([64, 64, 3, 3])\n",
      "backbone.2.bias \t torch.Size([64])\n",
      "backbone.5.weight \t torch.Size([128, 64, 3, 3])\n",
      "backbone.5.bias \t torch.Size([128])\n",
      "backbone.7.weight \t torch.Size([128, 128, 3, 3])\n",
      "backbone.7.bias \t torch.Size([128])\n",
      "backbone.10.weight \t torch.Size([256, 128, 3, 3])\n",
      "backbone.10.bias \t torch.Size([256])\n",
      "backbone.12.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.12.bias \t torch.Size([256])\n",
      "backbone.14.weight \t torch.Size([256, 256, 3, 3])\n",
      "backbone.14.bias \t torch.Size([256])\n",
      "backbone.17.weight \t torch.Size([512, 256, 3, 3])\n",
      "backbone.17.bias \t torch.Size([512])\n",
      "backbone.19.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.19.bias \t torch.Size([512])\n",
      "backbone.21.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.21.bias \t torch.Size([512])\n",
      "backbone.24.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.24.bias \t torch.Size([512])\n",
      "backbone.26.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.26.bias \t torch.Size([512])\n",
      "backbone.28.weight \t torch.Size([512, 512, 3, 3])\n",
      "backbone.28.bias \t torch.Size([512])\n",
      "head.classification_head.conv.0.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.classification_head.conv.0.bias \t torch.Size([512])\n",
      "head.classification_head.conv.2.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.classification_head.conv.2.bias \t torch.Size([512])\n",
      "head.classification_head.conv.4.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.classification_head.conv.4.bias \t torch.Size([512])\n",
      "head.classification_head.conv.6.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.classification_head.conv.6.bias \t torch.Size([512])\n",
      "head.classification_head.cls_logits.weight \t torch.Size([150, 512, 3, 3])\n",
      "head.classification_head.cls_logits.bias \t torch.Size([150])\n",
      "head.regression_head.conv.0.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.regression_head.conv.0.bias \t torch.Size([512])\n",
      "head.regression_head.conv.2.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.regression_head.conv.2.bias \t torch.Size([512])\n",
      "head.regression_head.conv.4.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.regression_head.conv.4.bias \t torch.Size([512])\n",
      "head.regression_head.conv.6.weight \t torch.Size([512, 512, 3, 3])\n",
      "head.regression_head.conv.6.bias \t torch.Size([512])\n",
      "head.regression_head.bbox_reg.weight \t torch.Size([60, 512, 3, 3])\n",
      "head.regression_head.bbox_reg.bias \t torch.Size([60])\n"
     ]
    }
   ],
   "source": [
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "processed-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_data(object):\n",
    "    def __init__(self, path, transforms):\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        self.imgs = list(sorted(os.listdir(path)))\n",
    "       \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        print(idx)\n",
    "        img_path = os.path.join(self.path, self.imgs[idx])\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "        return image\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hungarian-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'D:/Dataset/KITTI/testing/horizontal_shift'\n",
    "\n",
    "data = test_data(image_directory, transforms= testTensor())\n",
    "indices = torch.randperm(len(data))\n",
    "dataset = torch.utils.data.Subset(data, indices[:24])\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "electoral-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = DataLoader(dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "crude-prairie",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1076)\n",
      "tensor(4040)\n",
      "tensor(1017)\n",
      "tensor(4804)\n"
     ]
    }
   ],
   "source": [
    "image = next(iter(testdata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proper-explorer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 1200, 1200])\n",
      "torch.Size([4, 64, 600, 600])\n",
      "torch.Size([4, 128, 300, 300])\n",
      "torch.Size([4, 256, 150, 150])\n",
      "torch.Size([4, 512, 75, 75])\n",
      "torch.Size([4, 512, 37, 37])\n",
      "torch.Size([4, 512, 37, 37])\n",
      "torch.Size([4, 150, 37, 37])\n",
      "torch.Size([4, 512, 37, 37])\n",
      "torch.Size([4, 60, 37, 37])\n"
     ]
    }
   ],
   "source": [
    "out0 = image\n",
    "print(out0.shape)\n",
    "out1 = model.backbone[4](F.relu(model.backbone[2](F.relu(model.backbone[0](out0)))))\n",
    "print(out1.shape)\n",
    "out2 = model.backbone[9](F.relu(model.backbone[7](F.relu(model.backbone[5](out1)))))\n",
    "print(out2.shape)\n",
    "out3 = model.backbone[16](F.relu(model.backbone[14](F.relu(model.backbone[12](F.relu(model.backbone[10](out2)))))))        \n",
    "print(out3.shape)\n",
    "out4 = model.backbone[23](F.relu(model.backbone[21](F.relu(model.backbone[19](F.relu(model.backbone[17](out3)))))))    \n",
    "print(out4.shape)\n",
    "out5 = model.backbone[30](F.relu(model.backbone[28](F.relu(model.backbone[26](F.relu(model.backbone[24](out4)))))))\n",
    "print(out5.shape)\n",
    "out6 = F.relu(model.head.classification_head.conv[6](F.relu(model.head.classification_head.conv[4](F.relu(model.head.classification_head.conv[2](F.relu(model.head.classification_head.conv[0](out5))))))))\n",
    "print(out6.shape)\n",
    "out7 = model.head.classification_head.cls_logits(out6)\n",
    "print(out7.shape)\n",
    "out8 = F.relu(model.head.regression_head.conv[6](F.relu(model.head.regression_head.conv[4](F.relu(model.head.regression_head.conv[2](F.relu(model.head.regression_head.conv[0](out5))))))))\n",
    "print(out8.shape)\n",
    "out9 = model.head.regression_head.bbox_reg(out8)\n",
    "print(out9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "integrated-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeID(r, nres, fraction):\n",
    "    ID = []\n",
    "    n = int(np.round(r.shape[0]*fraction))\n",
    "    print(n)\n",
    "    dist = squareform(pdist(r, 'euclidean'))\n",
    "    print(dist)\n",
    "    for i in range(nres):\n",
    "        dist_s = dist\n",
    "        perm = np.random.permutation(dist.shape[0])[0:n]\n",
    "        print(perm)\n",
    "        dist_s = dist_s[perm,:]\n",
    "        dist_s = dist_s[:,perm]\n",
    "        print(dist_s)\n",
    "        ID.append(estimate(dist_s)[2])\n",
    "    mean = np.mean(ID)\n",
    "    error = np.std(ID)\n",
    "    return mean,error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "trying-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out0 = out0.view(image.shape[0], -1).cpu().data\n",
    "Out1 = out1.view(image.shape[0], -1).cpu().data\n",
    "Out2 = out2.view(image.shape[0], -1).cpu().data\n",
    "Out3 = out3.view(image.shape[0], -1).cpu().data\n",
    "Out4 = out4.view(image.shape[0], -1).cpu().data\n",
    "Out5 = out5.view(image.shape[0], -1).cpu().data\n",
    "Out6 = out6.view(image.shape[0], -1).cpu().data\n",
    "Out7 = out7.view(image.shape[0], -1).cpu().data\n",
    "Out8 = out8.view(image.shape[0], -1).cpu().data\n",
    "Out9 = out9.view(image.shape[0], -1).cpu().data\n",
    "#Out10 = out10.view(image.shape[0], -1).cpu().data\n",
    "#Out11 = out11.view(image.shape[0], -1).cpu().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "extreme-drunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "Out0 = torch.cat((Out0, out0.view(image.shape[0], -1).cpu().data),0)\n",
    "Out1 = torch.cat((Out1, out1.view(image.shape[0], -1).cpu().data),0) \n",
    "Out2 = torch.cat((Out2, out2.view(image.shape[0], -1).cpu().data),0) \n",
    "Out3 = torch.cat((Out3, out3.view(image.shape[0], -1).cpu().data),0)                 \n",
    "Out4 = torch.cat((Out4, out4.view(image.shape[0], -1).cpu().data),0) \n",
    "Out5 = torch.cat((Out5, out5.view(image.shape[0], -1).cpu().data),0) \n",
    "Out6 = torch.cat((Out6, out6.view(image.shape[0], -1).cpu().data),0) \n",
    "Out7 = torch.cat((Out7, out7.view(image.shape[0], -1).cpu().data),0)                 \n",
    "Out8 = torch.cat((Out8, out8.view(image.shape[0], -1).cpu().data),0)\n",
    "Out9 = torch.cat((Out9, out9.view(image.shape[0], -1).cpu().data),0) \n",
    "#Out10 = torch.cat((Out10, out10.view(image.shape[0], -1).cpu().data),0)                 \n",
    "#Out11 = torch.cat((Out11, out11.view(image.shape[0], -1).cpu().data),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "supported-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [Out0, Out1, Out2, Out3, Out4, Out5, Out6, Out7, Out8, Out9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "recognized-senior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 1.0000, 1.0000,  ..., 0.3451, 0.3412, 0.3373],\n",
      "        [0.8784, 0.8745, 0.8706,  ..., 0.0314, 0.0314, 0.0314],\n",
      "        [0.4039, 0.4275, 0.4078,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        ...,\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 0.3451, 0.3412, 0.3373],\n",
      "        [0.3686, 0.3451, 0.2627,  ..., 0.2353, 0.2471, 0.2510],\n",
      "        [0.2863, 0.3020, 0.3373,  ..., 0.8000, 0.7961, 0.7882]])\n",
      "7\n",
      "[[   0.          806.8415167  1122.34390633  778.71728191  687.7001802\n",
      "     0.          839.41353936  886.70098792]\n",
      " [ 806.8415167     0.         1141.2520599   912.16916656  701.88973729\n",
      "   806.8415167  1059.82332949 1127.53435898]\n",
      " [1122.34390633 1141.2520599     0.         1197.84663387  973.48172084\n",
      "  1122.34390633 1081.65726794  915.29330917]\n",
      " [ 778.71728191  912.16916656 1197.84663387    0.          885.66762548\n",
      "   778.71728191  959.89835336 1065.16496374]\n",
      " [ 687.7001802   701.88973729  973.48172084  885.66762548    0.\n",
      "   687.7001802   902.30639117  949.04501407]\n",
      " [   0.          806.8415167  1122.34390633  778.71728191  687.7001802\n",
      "     0.          839.41353936  886.70098792]\n",
      " [ 839.41353936 1059.82332949 1081.65726794  959.89835336  902.30639117\n",
      "   839.41353936    0.          864.65360158]\n",
      " [ 886.70098792 1127.53435898  915.29330917 1065.16496374  949.04501407\n",
      "   886.70098792  864.65360158    0.        ]]\n",
      "[6 4 2 7 0 1 5]\n",
      "[[   0.          902.30639117 1081.65726794  864.65360158  839.41353936\n",
      "  1059.82332949  839.41353936]\n",
      " [ 902.30639117    0.          973.48172084  949.04501407  687.7001802\n",
      "   701.88973729  687.7001802 ]\n",
      " [1081.65726794  973.48172084    0.          915.29330917 1122.34390633\n",
      "  1141.2520599  1122.34390633]\n",
      " [ 864.65360158  949.04501407  915.29330917    0.          886.70098792\n",
      "  1127.53435898  886.70098792]\n",
      " [ 839.41353936  687.7001802  1122.34390633  886.70098792    0.\n",
      "   806.8415167     0.        ]\n",
      " [1059.82332949  701.88973729 1141.2520599  1127.53435898  806.8415167\n",
      "     0.          806.8415167 ]\n",
      " [ 839.41353936  687.7001802  1122.34390633  886.70098792    0.\n",
      "   806.8415167     0.        ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have length at least 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a00f81bf9de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mID_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputeID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mID_all\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-df0b548cdcd7>\u001b[0m in \u001b[0;36mcomputeID\u001b[1;34m(r, nres, fraction)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mdist_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist_s\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mID\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Guided Research\\ID\\ID\\intrinsic_dimension.py\u001b[0m in \u001b[0;36mestimate\u001b[1;34m(X, fraction, verbose)\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnpoints\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   3904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3905\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3906\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'x and y must have length at least 2.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3908\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have length at least 2."
     ]
    }
   ],
   "source": [
    "ID_all = []\n",
    "for j in tqdm(range(0,12)):\n",
    "    r = out[j]\n",
    "    print(r)\n",
    "    ID_all.append(computeID(r, 20, 0.9))\n",
    "ID_all = np.array(ID_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "industrial-affair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(26.09362889859936, 3.552713678800501e-15),\n",
       " (11.292461444869833, 3.552713678800501e-15),\n",
       " (11.937158710242844, 0.0),\n",
       " (7.698880093808394, 1.7763568394002505e-15),\n",
       " (11.654509692911462, 0.0),\n",
       " (34.401205237992244, 0.0),\n",
       " (18.871602110210368, 7.105427357601002e-15),\n",
       " (21.29145392917633, 0.0),\n",
       " (20.512634611260175, 3.552713678800501e-15),\n",
       " (93.92338438867301, 1.4210854715202004e-14)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "surprising-trailer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-algebra",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
